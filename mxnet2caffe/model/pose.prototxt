name: "mxnet-mdoel"
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape: { dim: 1 dim: 3 dim: 112 dim: 112 }
  }
}

layer {
	bottom: "data"
	top: "conv0"
	name: "conv0"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		group: 1
		stride: 2
		bias_term: false
	}
}

layer {
  bottom: "conv0"
  top: "batchnorm0"
  name: "batchnorm0"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "batchnorm0"
  top: "batchnorm0"
  name: "batchnorm0_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "batchnorm0"
  top: "prelu0"
  name: "prelu0"
  type: "PReLU"
}

layer {
	bottom: "prelu0"
	top: "conv1"
	name: "conv1"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		group: 64
		engine: CAFFE
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv1"
  top: "batchnorm1"
  name: "batchnorm1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "batchnorm1"
  top: "batchnorm1"
  name: "batchnorm1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "batchnorm1"
  top: "prelu1"
  name: "prelu1"
  type: "PReLU"
}

layer {
	bottom: "prelu1"
	top: "stage1_bottleneck0_conv0"
	name: "stage1_bottleneck0_conv0"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage1_bottleneck0_conv0"
  top: "stage1_bottleneck0_batchnorm0"
  name: "stage1_bottleneck0_batchnorm0"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage1_bottleneck0_batchnorm0"
  top: "stage1_bottleneck0_batchnorm0"
  name: "stage1_bottleneck0_batchnorm0_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage1_bottleneck0_batchnorm0"
  top: "stage1_bottleneck0_prelu0"
  name: "stage1_bottleneck0_prelu0"
  type: "PReLU"
}

layer {
	bottom: "stage1_bottleneck0_prelu0"
	top: "stage1_bottleneck0_conv1"
	name: "stage1_bottleneck0_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		group: 128
		engine: CAFFE
		stride: 2
		bias_term: false
	}
}

layer {
  bottom: "stage1_bottleneck0_conv1"
  top: "stage1_bottleneck0_batchnorm1"
  name: "stage1_bottleneck0_batchnorm1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage1_bottleneck0_batchnorm1"
  top: "stage1_bottleneck0_batchnorm1"
  name: "stage1_bottleneck0_batchnorm1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage1_bottleneck0_batchnorm1"
  top: "stage1_bottleneck0_prelu1"
  name: "stage1_bottleneck0_prelu1"
  type: "PReLU"
}

layer {
	bottom: "stage1_bottleneck0_prelu1"
	top: "stage1_bottleneck0_conv2"
	name: "stage1_bottleneck0_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage1_bottleneck0_conv2"
  top: "stage1_bottleneck0_batchnorm2"
  name: "stage1_bottleneck0_batchnorm2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage1_bottleneck0_batchnorm2"
  top: "stage1_bottleneck0_batchnorm2"
  name: "stage1_bottleneck0_batchnorm2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
	bottom: "stage1_bottleneck0_batchnorm2"
	top: "stage1_bottleneck1_conv0"
	name: "stage1_bottleneck1_conv0"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage1_bottleneck1_conv0"
  top: "stage1_bottleneck1_batchnorm0"
  name: "stage1_bottleneck1_batchnorm0"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage1_bottleneck1_batchnorm0"
  top: "stage1_bottleneck1_batchnorm0"
  name: "stage1_bottleneck1_batchnorm0_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage1_bottleneck1_batchnorm0"
  top: "stage1_bottleneck1_prelu0"
  name: "stage1_bottleneck1_prelu0"
  type: "PReLU"
}

layer {
	bottom: "stage1_bottleneck1_prelu0"
	top: "stage1_bottleneck1_conv1"
	name: "stage1_bottleneck1_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		group: 128
		engine: CAFFE
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage1_bottleneck1_conv1"
  top: "stage1_bottleneck1_batchnorm1"
  name: "stage1_bottleneck1_batchnorm1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage1_bottleneck1_batchnorm1"
  top: "stage1_bottleneck1_batchnorm1"
  name: "stage1_bottleneck1_batchnorm1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage1_bottleneck1_batchnorm1"
  top: "stage1_bottleneck1_prelu1"
  name: "stage1_bottleneck1_prelu1"
  type: "PReLU"
}

layer {
	bottom: "stage1_bottleneck1_prelu1"
	top: "stage1_bottleneck1_conv2"
	name: "stage1_bottleneck1_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage1_bottleneck1_conv2"
  top: "stage1_bottleneck1_batchnorm2"
  name: "stage1_bottleneck1_batchnorm2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage1_bottleneck1_batchnorm2"
  top: "stage1_bottleneck1_batchnorm2"
  name: "stage1_bottleneck1_batchnorm2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  type: "Eltwise"
  top: "stage1_bottleneck1_elemwise_add0"
  name: "stage1_bottleneck1_elemwise_add0"
  bottom: "stage1_bottleneck1_batchnorm2"
  bottom: "stage1_bottleneck0_batchnorm2"
  eltwise_param { operation: SUM }
}

layer {
	bottom: "stage1_bottleneck1_elemwise_add0"
	top: "stage1_bottleneck2_conv0"
	name: "stage1_bottleneck2_conv0"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage1_bottleneck2_conv0"
  top: "stage1_bottleneck2_batchnorm0"
  name: "stage1_bottleneck2_batchnorm0"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage1_bottleneck2_batchnorm0"
  top: "stage1_bottleneck2_batchnorm0"
  name: "stage1_bottleneck2_batchnorm0_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage1_bottleneck2_batchnorm0"
  top: "stage1_bottleneck2_prelu0"
  name: "stage1_bottleneck2_prelu0"
  type: "PReLU"
}

layer {
	bottom: "stage1_bottleneck2_prelu0"
	top: "stage1_bottleneck2_conv1"
	name: "stage1_bottleneck2_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		group: 128
		engine: CAFFE
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage1_bottleneck2_conv1"
  top: "stage1_bottleneck2_batchnorm1"
  name: "stage1_bottleneck2_batchnorm1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage1_bottleneck2_batchnorm1"
  top: "stage1_bottleneck2_batchnorm1"
  name: "stage1_bottleneck2_batchnorm1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage1_bottleneck2_batchnorm1"
  top: "stage1_bottleneck2_prelu1"
  name: "stage1_bottleneck2_prelu1"
  type: "PReLU"
}

layer {
	bottom: "stage1_bottleneck2_prelu1"
	top: "stage1_bottleneck2_conv2"
	name: "stage1_bottleneck2_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage1_bottleneck2_conv2"
  top: "stage1_bottleneck2_batchnorm2"
  name: "stage1_bottleneck2_batchnorm2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage1_bottleneck2_batchnorm2"
  top: "stage1_bottleneck2_batchnorm2"
  name: "stage1_bottleneck2_batchnorm2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  type: "Eltwise"
  top: "stage1_bottleneck2_elemwise_add0"
  name: "stage1_bottleneck2_elemwise_add0"
  bottom: "stage1_bottleneck2_batchnorm2"
  bottom: "stage1_bottleneck1_elemwise_add0"
  eltwise_param { operation: SUM }
}

layer {
	bottom: "stage1_bottleneck2_elemwise_add0"
	top: "stage1_bottleneck3_conv0"
	name: "stage1_bottleneck3_conv0"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage1_bottleneck3_conv0"
  top: "stage1_bottleneck3_batchnorm0"
  name: "stage1_bottleneck3_batchnorm0"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage1_bottleneck3_batchnorm0"
  top: "stage1_bottleneck3_batchnorm0"
  name: "stage1_bottleneck3_batchnorm0_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage1_bottleneck3_batchnorm0"
  top: "stage1_bottleneck3_prelu0"
  name: "stage1_bottleneck3_prelu0"
  type: "PReLU"
}

layer {
	bottom: "stage1_bottleneck3_prelu0"
	top: "stage1_bottleneck3_conv1"
	name: "stage1_bottleneck3_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		group: 128
		engine: CAFFE
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage1_bottleneck3_conv1"
  top: "stage1_bottleneck3_batchnorm1"
  name: "stage1_bottleneck3_batchnorm1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage1_bottleneck3_batchnorm1"
  top: "stage1_bottleneck3_batchnorm1"
  name: "stage1_bottleneck3_batchnorm1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage1_bottleneck3_batchnorm1"
  top: "stage1_bottleneck3_prelu1"
  name: "stage1_bottleneck3_prelu1"
  type: "PReLU"
}

layer {
	bottom: "stage1_bottleneck3_prelu1"
	top: "stage1_bottleneck3_conv2"
	name: "stage1_bottleneck3_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage1_bottleneck3_conv2"
  top: "stage1_bottleneck3_batchnorm2"
  name: "stage1_bottleneck3_batchnorm2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage1_bottleneck3_batchnorm2"
  top: "stage1_bottleneck3_batchnorm2"
  name: "stage1_bottleneck3_batchnorm2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  type: "Eltwise"
  top: "stage1_bottleneck3_elemwise_add0"
  name: "stage1_bottleneck3_elemwise_add0"
  bottom: "stage1_bottleneck3_batchnorm2"
  bottom: "stage1_bottleneck2_elemwise_add0"
  eltwise_param { operation: SUM }
}

layer {
	bottom: "stage1_bottleneck3_elemwise_add0"
	top: "stage1_bottleneck4_conv0"
	name: "stage1_bottleneck4_conv0"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage1_bottleneck4_conv0"
  top: "stage1_bottleneck4_batchnorm0"
  name: "stage1_bottleneck4_batchnorm0"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage1_bottleneck4_batchnorm0"
  top: "stage1_bottleneck4_batchnorm0"
  name: "stage1_bottleneck4_batchnorm0_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage1_bottleneck4_batchnorm0"
  top: "stage1_bottleneck4_prelu0"
  name: "stage1_bottleneck4_prelu0"
  type: "PReLU"
}

layer {
	bottom: "stage1_bottleneck4_prelu0"
	top: "stage1_bottleneck4_conv1"
	name: "stage1_bottleneck4_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		group: 128
		engine: CAFFE
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage1_bottleneck4_conv1"
  top: "stage1_bottleneck4_batchnorm1"
  name: "stage1_bottleneck4_batchnorm1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage1_bottleneck4_batchnorm1"
  top: "stage1_bottleneck4_batchnorm1"
  name: "stage1_bottleneck4_batchnorm1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage1_bottleneck4_batchnorm1"
  top: "stage1_bottleneck4_prelu1"
  name: "stage1_bottleneck4_prelu1"
  type: "PReLU"
}

layer {
	bottom: "stage1_bottleneck4_prelu1"
	top: "stage1_bottleneck4_conv2"
	name: "stage1_bottleneck4_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage1_bottleneck4_conv2"
  top: "stage1_bottleneck4_batchnorm2"
  name: "stage1_bottleneck4_batchnorm2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage1_bottleneck4_batchnorm2"
  top: "stage1_bottleneck4_batchnorm2"
  name: "stage1_bottleneck4_batchnorm2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  type: "Eltwise"
  top: "stage1_bottleneck4_elemwise_add0"
  name: "stage1_bottleneck4_elemwise_add0"
  bottom: "stage1_bottleneck4_batchnorm2"
  bottom: "stage1_bottleneck3_elemwise_add0"
  eltwise_param { operation: SUM }
}

layer {
	bottom: "stage1_bottleneck4_elemwise_add0"
	top: "stage2_bottleneck0_conv0"
	name: "stage2_bottleneck0_conv0"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage2_bottleneck0_conv0"
  top: "stage2_bottleneck0_batchnorm0"
  name: "stage2_bottleneck0_batchnorm0"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage2_bottleneck0_batchnorm0"
  top: "stage2_bottleneck0_batchnorm0"
  name: "stage2_bottleneck0_batchnorm0_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage2_bottleneck0_batchnorm0"
  top: "stage2_bottleneck0_prelu0"
  name: "stage2_bottleneck0_prelu0"
  type: "PReLU"
}

layer {
	bottom: "stage2_bottleneck0_prelu0"
	top: "stage2_bottleneck0_conv1"
	name: "stage2_bottleneck0_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		group: 256
		engine: CAFFE
		stride: 2
		bias_term: false
	}
}

layer {
  bottom: "stage2_bottleneck0_conv1"
  top: "stage2_bottleneck0_batchnorm1"
  name: "stage2_bottleneck0_batchnorm1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage2_bottleneck0_batchnorm1"
  top: "stage2_bottleneck0_batchnorm1"
  name: "stage2_bottleneck0_batchnorm1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage2_bottleneck0_batchnorm1"
  top: "stage2_bottleneck0_prelu1"
  name: "stage2_bottleneck0_prelu1"
  type: "PReLU"
}

layer {
	bottom: "stage2_bottleneck0_prelu1"
	top: "stage2_bottleneck0_conv2"
	name: "stage2_bottleneck0_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage2_bottleneck0_conv2"
  top: "stage2_bottleneck0_batchnorm2"
  name: "stage2_bottleneck0_batchnorm2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage2_bottleneck0_batchnorm2"
  top: "stage2_bottleneck0_batchnorm2"
  name: "stage2_bottleneck0_batchnorm2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
	bottom: "stage2_bottleneck0_batchnorm2"
	top: "stage3_bottleneck0_conv0"
	name: "stage3_bottleneck0_conv0"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck0_conv0"
  top: "stage3_bottleneck0_batchnorm0"
  name: "stage3_bottleneck0_batchnorm0"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck0_batchnorm0"
  top: "stage3_bottleneck0_batchnorm0"
  name: "stage3_bottleneck0_batchnorm0_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_bottleneck0_batchnorm0"
  top: "stage3_bottleneck0_prelu0"
  name: "stage3_bottleneck0_prelu0"
  type: "PReLU"
}

layer {
	bottom: "stage3_bottleneck0_prelu0"
	top: "stage3_bottleneck0_conv1"
	name: "stage3_bottleneck0_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		group: 256
		engine: CAFFE
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck0_conv1"
  top: "stage3_bottleneck0_batchnorm1"
  name: "stage3_bottleneck0_batchnorm1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck0_batchnorm1"
  top: "stage3_bottleneck0_batchnorm1"
  name: "stage3_bottleneck0_batchnorm1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_bottleneck0_batchnorm1"
  top: "stage3_bottleneck0_prelu1"
  name: "stage3_bottleneck0_prelu1"
  type: "PReLU"
}

layer {
	bottom: "stage3_bottleneck0_prelu1"
	top: "stage3_bottleneck0_conv2"
	name: "stage3_bottleneck0_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck0_conv2"
  top: "stage3_bottleneck0_batchnorm2"
  name: "stage3_bottleneck0_batchnorm2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck0_batchnorm2"
  top: "stage3_bottleneck0_batchnorm2"
  name: "stage3_bottleneck0_batchnorm2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  type: "Eltwise"
  top: "stage3_bottleneck0_elemwise_add0"
  name: "stage3_bottleneck0_elemwise_add0"
  bottom: "stage3_bottleneck0_batchnorm2"
  bottom: "stage2_bottleneck0_batchnorm2"
  eltwise_param { operation: SUM }
}

layer {
	bottom: "stage3_bottleneck0_elemwise_add0"
	top: "stage3_bottleneck1_conv0"
	name: "stage3_bottleneck1_conv0"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck1_conv0"
  top: "stage3_bottleneck1_batchnorm0"
  name: "stage3_bottleneck1_batchnorm0"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck1_batchnorm0"
  top: "stage3_bottleneck1_batchnorm0"
  name: "stage3_bottleneck1_batchnorm0_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_bottleneck1_batchnorm0"
  top: "stage3_bottleneck1_prelu0"
  name: "stage3_bottleneck1_prelu0"
  type: "PReLU"
}

layer {
	bottom: "stage3_bottleneck1_prelu0"
	top: "stage3_bottleneck1_conv1"
	name: "stage3_bottleneck1_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		group: 256
		engine: CAFFE
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck1_conv1"
  top: "stage3_bottleneck1_batchnorm1"
  name: "stage3_bottleneck1_batchnorm1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck1_batchnorm1"
  top: "stage3_bottleneck1_batchnorm1"
  name: "stage3_bottleneck1_batchnorm1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_bottleneck1_batchnorm1"
  top: "stage3_bottleneck1_prelu1"
  name: "stage3_bottleneck1_prelu1"
  type: "PReLU"
}

layer {
	bottom: "stage3_bottleneck1_prelu1"
	top: "stage3_bottleneck1_conv2"
	name: "stage3_bottleneck1_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck1_conv2"
  top: "stage3_bottleneck1_batchnorm2"
  name: "stage3_bottleneck1_batchnorm2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck1_batchnorm2"
  top: "stage3_bottleneck1_batchnorm2"
  name: "stage3_bottleneck1_batchnorm2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  type: "Eltwise"
  top: "stage3_bottleneck1_elemwise_add0"
  name: "stage3_bottleneck1_elemwise_add0"
  bottom: "stage3_bottleneck1_batchnorm2"
  bottom: "stage3_bottleneck0_elemwise_add0"
  eltwise_param { operation: SUM }
}

layer {
	bottom: "stage3_bottleneck1_elemwise_add0"
	top: "stage3_bottleneck2_conv0"
	name: "stage3_bottleneck2_conv0"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck2_conv0"
  top: "stage3_bottleneck2_batchnorm0"
  name: "stage3_bottleneck2_batchnorm0"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck2_batchnorm0"
  top: "stage3_bottleneck2_batchnorm0"
  name: "stage3_bottleneck2_batchnorm0_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_bottleneck2_batchnorm0"
  top: "stage3_bottleneck2_prelu0"
  name: "stage3_bottleneck2_prelu0"
  type: "PReLU"
}

layer {
	bottom: "stage3_bottleneck2_prelu0"
	top: "stage3_bottleneck2_conv1"
	name: "stage3_bottleneck2_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		group: 256
		engine: CAFFE
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck2_conv1"
  top: "stage3_bottleneck2_batchnorm1"
  name: "stage3_bottleneck2_batchnorm1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck2_batchnorm1"
  top: "stage3_bottleneck2_batchnorm1"
  name: "stage3_bottleneck2_batchnorm1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_bottleneck2_batchnorm1"
  top: "stage3_bottleneck2_prelu1"
  name: "stage3_bottleneck2_prelu1"
  type: "PReLU"
}

layer {
	bottom: "stage3_bottleneck2_prelu1"
	top: "stage3_bottleneck2_conv2"
	name: "stage3_bottleneck2_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck2_conv2"
  top: "stage3_bottleneck2_batchnorm2"
  name: "stage3_bottleneck2_batchnorm2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck2_batchnorm2"
  top: "stage3_bottleneck2_batchnorm2"
  name: "stage3_bottleneck2_batchnorm2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  type: "Eltwise"
  top: "stage3_bottleneck2_elemwise_add0"
  name: "stage3_bottleneck2_elemwise_add0"
  bottom: "stage3_bottleneck2_batchnorm2"
  bottom: "stage3_bottleneck1_elemwise_add0"
  eltwise_param { operation: SUM }
}

layer {
	bottom: "stage3_bottleneck2_elemwise_add0"
	top: "stage3_bottleneck3_conv0"
	name: "stage3_bottleneck3_conv0"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck3_conv0"
  top: "stage3_bottleneck3_batchnorm0"
  name: "stage3_bottleneck3_batchnorm0"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck3_batchnorm0"
  top: "stage3_bottleneck3_batchnorm0"
  name: "stage3_bottleneck3_batchnorm0_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_bottleneck3_batchnorm0"
  top: "stage3_bottleneck3_prelu0"
  name: "stage3_bottleneck3_prelu0"
  type: "PReLU"
}

layer {
	bottom: "stage3_bottleneck3_prelu0"
	top: "stage3_bottleneck3_conv1"
	name: "stage3_bottleneck3_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		group: 256
		engine: CAFFE
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck3_conv1"
  top: "stage3_bottleneck3_batchnorm1"
  name: "stage3_bottleneck3_batchnorm1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck3_batchnorm1"
  top: "stage3_bottleneck3_batchnorm1"
  name: "stage3_bottleneck3_batchnorm1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_bottleneck3_batchnorm1"
  top: "stage3_bottleneck3_prelu1"
  name: "stage3_bottleneck3_prelu1"
  type: "PReLU"
}

layer {
	bottom: "stage3_bottleneck3_prelu1"
	top: "stage3_bottleneck3_conv2"
	name: "stage3_bottleneck3_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck3_conv2"
  top: "stage3_bottleneck3_batchnorm2"
  name: "stage3_bottleneck3_batchnorm2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck3_batchnorm2"
  top: "stage3_bottleneck3_batchnorm2"
  name: "stage3_bottleneck3_batchnorm2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  type: "Eltwise"
  top: "stage3_bottleneck3_elemwise_add0"
  name: "stage3_bottleneck3_elemwise_add0"
  bottom: "stage3_bottleneck3_batchnorm2"
  bottom: "stage3_bottleneck2_elemwise_add0"
  eltwise_param { operation: SUM }
}

layer {
	bottom: "stage3_bottleneck3_elemwise_add0"
	top: "stage3_bottleneck4_conv0"
	name: "stage3_bottleneck4_conv0"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck4_conv0"
  top: "stage3_bottleneck4_batchnorm0"
  name: "stage3_bottleneck4_batchnorm0"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck4_batchnorm0"
  top: "stage3_bottleneck4_batchnorm0"
  name: "stage3_bottleneck4_batchnorm0_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_bottleneck4_batchnorm0"
  top: "stage3_bottleneck4_prelu0"
  name: "stage3_bottleneck4_prelu0"
  type: "PReLU"
}

layer {
	bottom: "stage3_bottleneck4_prelu0"
	top: "stage3_bottleneck4_conv1"
	name: "stage3_bottleneck4_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		group: 256
		engine: CAFFE
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck4_conv1"
  top: "stage3_bottleneck4_batchnorm1"
  name: "stage3_bottleneck4_batchnorm1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck4_batchnorm1"
  top: "stage3_bottleneck4_batchnorm1"
  name: "stage3_bottleneck4_batchnorm1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_bottleneck4_batchnorm1"
  top: "stage3_bottleneck4_prelu1"
  name: "stage3_bottleneck4_prelu1"
  type: "PReLU"
}

layer {
	bottom: "stage3_bottleneck4_prelu1"
	top: "stage3_bottleneck4_conv2"
	name: "stage3_bottleneck4_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck4_conv2"
  top: "stage3_bottleneck4_batchnorm2"
  name: "stage3_bottleneck4_batchnorm2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck4_batchnorm2"
  top: "stage3_bottleneck4_batchnorm2"
  name: "stage3_bottleneck4_batchnorm2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  type: "Eltwise"
  top: "stage3_bottleneck4_elemwise_add0"
  name: "stage3_bottleneck4_elemwise_add0"
  bottom: "stage3_bottleneck4_batchnorm2"
  bottom: "stage3_bottleneck3_elemwise_add0"
  eltwise_param { operation: SUM }
}

layer {
	bottom: "stage3_bottleneck4_elemwise_add0"
	top: "stage3_bottleneck5_conv0"
	name: "stage3_bottleneck5_conv0"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck5_conv0"
  top: "stage3_bottleneck5_batchnorm0"
  name: "stage3_bottleneck5_batchnorm0"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck5_batchnorm0"
  top: "stage3_bottleneck5_batchnorm0"
  name: "stage3_bottleneck5_batchnorm0_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_bottleneck5_batchnorm0"
  top: "stage3_bottleneck5_prelu0"
  name: "stage3_bottleneck5_prelu0"
  type: "PReLU"
}

layer {
	bottom: "stage3_bottleneck5_prelu0"
	top: "stage3_bottleneck5_conv1"
	name: "stage3_bottleneck5_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		group: 256
		engine: CAFFE
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck5_conv1"
  top: "stage3_bottleneck5_batchnorm1"
  name: "stage3_bottleneck5_batchnorm1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck5_batchnorm1"
  top: "stage3_bottleneck5_batchnorm1"
  name: "stage3_bottleneck5_batchnorm1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_bottleneck5_batchnorm1"
  top: "stage3_bottleneck5_prelu1"
  name: "stage3_bottleneck5_prelu1"
  type: "PReLU"
}

layer {
	bottom: "stage3_bottleneck5_prelu1"
	top: "stage3_bottleneck5_conv2"
	name: "stage3_bottleneck5_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_bottleneck5_conv2"
  top: "stage3_bottleneck5_batchnorm2"
  name: "stage3_bottleneck5_batchnorm2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage3_bottleneck5_batchnorm2"
  top: "stage3_bottleneck5_batchnorm2"
  name: "stage3_bottleneck5_batchnorm2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  type: "Eltwise"
  top: "stage3_bottleneck5_elemwise_add0"
  name: "stage3_bottleneck5_elemwise_add0"
  bottom: "stage3_bottleneck5_batchnorm2"
  bottom: "stage3_bottleneck4_elemwise_add0"
  eltwise_param { operation: SUM }
}

layer {
	bottom: "stage3_bottleneck5_elemwise_add0"
	top: "stage4_bottleneck0_conv0"
	name: "stage4_bottleneck0_conv0"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage4_bottleneck0_conv0"
  top: "stage4_bottleneck0_batchnorm0"
  name: "stage4_bottleneck0_batchnorm0"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage4_bottleneck0_batchnorm0"
  top: "stage4_bottleneck0_batchnorm0"
  name: "stage4_bottleneck0_batchnorm0_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage4_bottleneck0_batchnorm0"
  top: "stage4_bottleneck0_prelu0"
  name: "stage4_bottleneck0_prelu0"
  type: "PReLU"
}

layer {
	bottom: "stage4_bottleneck0_prelu0"
	top: "stage4_bottleneck0_conv1"
	name: "stage4_bottleneck0_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		group: 512
		engine: CAFFE
		stride: 2
		bias_term: false
	}
}

layer {
  bottom: "stage4_bottleneck0_conv1"
  top: "stage4_bottleneck0_batchnorm1"
  name: "stage4_bottleneck0_batchnorm1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage4_bottleneck0_batchnorm1"
  top: "stage4_bottleneck0_batchnorm1"
  name: "stage4_bottleneck0_batchnorm1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage4_bottleneck0_batchnorm1"
  top: "stage4_bottleneck0_prelu1"
  name: "stage4_bottleneck0_prelu1"
  type: "PReLU"
}

layer {
	bottom: "stage4_bottleneck0_prelu1"
	top: "stage4_bottleneck0_conv2"
	name: "stage4_bottleneck0_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage4_bottleneck0_conv2"
  top: "stage4_bottleneck0_batchnorm2"
  name: "stage4_bottleneck0_batchnorm2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage4_bottleneck0_batchnorm2"
  top: "stage4_bottleneck0_batchnorm2"
  name: "stage4_bottleneck0_batchnorm2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
	bottom: "stage4_bottleneck0_batchnorm2"
	top: "stage5_bottleneck0_conv0"
	name: "stage5_bottleneck0_conv0"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage5_bottleneck0_conv0"
  top: "stage5_bottleneck0_batchnorm0"
  name: "stage5_bottleneck0_batchnorm0"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage5_bottleneck0_batchnorm0"
  top: "stage5_bottleneck0_batchnorm0"
  name: "stage5_bottleneck0_batchnorm0_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage5_bottleneck0_batchnorm0"
  top: "stage5_bottleneck0_prelu0"
  name: "stage5_bottleneck0_prelu0"
  type: "PReLU"
}

layer {
	bottom: "stage5_bottleneck0_prelu0"
	top: "stage5_bottleneck0_conv1"
	name: "stage5_bottleneck0_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		group: 256
		engine: CAFFE
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage5_bottleneck0_conv1"
  top: "stage5_bottleneck0_batchnorm1"
  name: "stage5_bottleneck0_batchnorm1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage5_bottleneck0_batchnorm1"
  top: "stage5_bottleneck0_batchnorm1"
  name: "stage5_bottleneck0_batchnorm1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage5_bottleneck0_batchnorm1"
  top: "stage5_bottleneck0_prelu1"
  name: "stage5_bottleneck0_prelu1"
  type: "PReLU"
}

layer {
	bottom: "stage5_bottleneck0_prelu1"
	top: "stage5_bottleneck0_conv2"
	name: "stage5_bottleneck0_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage5_bottleneck0_conv2"
  top: "stage5_bottleneck0_batchnorm2"
  name: "stage5_bottleneck0_batchnorm2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage5_bottleneck0_batchnorm2"
  top: "stage5_bottleneck0_batchnorm2"
  name: "stage5_bottleneck0_batchnorm2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  type: "Eltwise"
  top: "stage5_bottleneck0_elemwise_add0"
  name: "stage5_bottleneck0_elemwise_add0"
  bottom: "stage5_bottleneck0_batchnorm2"
  bottom: "stage4_bottleneck0_batchnorm2"
  eltwise_param { operation: SUM }
}

layer {
	bottom: "stage5_bottleneck0_elemwise_add0"
	top: "stage5_bottleneck1_conv0"
	name: "stage5_bottleneck1_conv0"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage5_bottleneck1_conv0"
  top: "stage5_bottleneck1_batchnorm0"
  name: "stage5_bottleneck1_batchnorm0"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage5_bottleneck1_batchnorm0"
  top: "stage5_bottleneck1_batchnorm0"
  name: "stage5_bottleneck1_batchnorm0_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage5_bottleneck1_batchnorm0"
  top: "stage5_bottleneck1_prelu0"
  name: "stage5_bottleneck1_prelu0"
  type: "PReLU"
}

layer {
	bottom: "stage5_bottleneck1_prelu0"
	top: "stage5_bottleneck1_conv1"
	name: "stage5_bottleneck1_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		group: 256
		engine: CAFFE
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage5_bottleneck1_conv1"
  top: "stage5_bottleneck1_batchnorm1"
  name: "stage5_bottleneck1_batchnorm1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage5_bottleneck1_batchnorm1"
  top: "stage5_bottleneck1_batchnorm1"
  name: "stage5_bottleneck1_batchnorm1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage5_bottleneck1_batchnorm1"
  top: "stage5_bottleneck1_prelu1"
  name: "stage5_bottleneck1_prelu1"
  type: "PReLU"
}

layer {
	bottom: "stage5_bottleneck1_prelu1"
	top: "stage5_bottleneck1_conv2"
	name: "stage5_bottleneck1_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage5_bottleneck1_conv2"
  top: "stage5_bottleneck1_batchnorm2"
  name: "stage5_bottleneck1_batchnorm2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "stage5_bottleneck1_batchnorm2"
  top: "stage5_bottleneck1_batchnorm2"
  name: "stage5_bottleneck1_batchnorm2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  type: "Eltwise"
  top: "stage5_bottleneck1_elemwise_add0"
  name: "stage5_bottleneck1_elemwise_add0"
  bottom: "stage5_bottleneck1_batchnorm2"
  bottom: "stage5_bottleneck0_elemwise_add0"
  eltwise_param { operation: SUM }
}

layer {
	bottom: "stage5_bottleneck1_elemwise_add0"
	top: "conv2"
	name: "conv2"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		group: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv2"
  top: "batchnorm2"
  name: "batchnorm2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "batchnorm2"
  top: "batchnorm2"
  name: "batchnorm2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "batchnorm2"
  top: "prelu2"
  name: "prelu2"
  type: "PReLU"
}

layer {
	bottom: "prelu2"
	top: "conv3"
	name: "conv3"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 7
		pad: 0
		group: 512
		engine: CAFFE
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv3"
  top: "batchnorm3"
  name: "batchnorm3"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 1e-05
  }
}
layer {
  bottom: "batchnorm3"
  top: "batchnorm3"
  name: "batchnorm3_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "batchnorm3"
  top: "fc_bin"
  name: "fc_bin"
  type: "InnerProduct"
  inner_product_param {
    num_output: 198
  }
}

layer {
  bottom: "fc_bin"
  top: "fc_pyr"
  name: "fc_pyr"
  type: "InnerProduct"
  inner_product_param {
    num_output: 3
  }
}

